{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a9d081",
   "metadata": {},
   "source": [
    "# Sequential pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6a8ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hf_models/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import environ\n",
    "environ.setdefault(\"HF_HOME\", \"/data/hf_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061bdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9279a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_design_pattern.agent import AgentMessage, LLMChain, BaseAgent\n",
    "from agent_design_pattern.orchestration import SequentialAgent\n",
    "from chain import CasualSingleTurnChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225acc3",
   "metadata": {},
   "source": [
    "## Define the agent\n",
    "\n",
    "Create a simple agent for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103d5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionImplementationAgent(BaseAgent):\n",
    "    def __init__(self, llm_chain: LLMChain, state_change_callback = None, name = None, **kwargs):\n",
    "        super().__init__(state_change_callback, name, **kwargs)\n",
    "        self.llm_chain = llm_chain\n",
    "\n",
    "    def execute(self, message: AgentMessage, **kwargs):\n",
    "        return self.llm_chain.invoke(message, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95fc70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [06:11<00:00, 92.76s/it] \n",
      "CUDA-fused xIELU not available (No module named 'xielu') – falling back to a Python version.\n",
      "For CUDA xIELU (experimental), `pip install git+https://github.com/nickjbrowning/XIELU`\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.10s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\n",
      "The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n"
     ]
    }
   ],
   "source": [
    "code_system_prompt = \"\"\"You are a helpful coding assistant.\n",
    "You task is to write a python function and return the implementation of the function.\n",
    "Just the implementation, DO NOT comment anything else\"\"\"\n",
    "code_user_prompt = \"{query}\"\n",
    "code_chain = CasualSingleTurnChain(\"swiss-ai/Apertus-8B-Instruct-2509\", code_system_prompt, code_user_prompt)\n",
    "\n",
    "doc_system_prompt = \"\"\"You are a great developer avocate.\n",
    "You task is to write a document and in-code explain for the function.\n",
    "Just the comment and explanation, DO NOT change the logic of the provided function.\n",
    "The response should contain function with docstring explanation. And DO NOT contain explanation outside of the code\"\"\"\n",
    "doc_user_prompt = \"\"\"Input query: {query}\n",
    "\n",
    "Function implementation: {response}\n",
    "\"\"\"\n",
    "doc_chain = CasualSingleTurnChain(\"HuggingFaceTB/SmolLM3-3B\", doc_system_prompt, doc_user_prompt)\n",
    "\n",
    "review_system_prompt = \"\"\"You are a excellent code reviewer and refactor.\n",
    "Given a function implementation and it explanation, your task is to review and code and correct if contains any mistake.\n",
    "Some note:\n",
    "- For the implementation, check if the orignal query and suggested implementation are match.\n",
    "- Is there any syntax error in the code.\n",
    "- For the explanation, verify if the docstring follows Google style docstring.\n",
    "- In the docstring, make sure to have an example to call the function.\n",
    "\n",
    "Make sure the final output only contain code, inline code comment and docstring, nothing else.\"\"\"\n",
    "review_user_prompt = \"\"\"Input query: {query}\n",
    "\n",
    "Function implementation: {response}\n",
    "\"\"\"\n",
    "review_chain = CasualSingleTurnChain(\"ibm-granite/granite-4.0-h-1b\", review_system_prompt, review_user_prompt)\n",
    "\n",
    "def state_callback(message: str):\n",
    "    print(message)\n",
    "\n",
    "code_agent = FunctionImplementationAgent(code_chain, state_change_callback=state_callback, name=\"Code Agent\")\n",
    "doc_agent = FunctionImplementationAgent(doc_chain, state_change_callback=state_callback, name=\"Docstring Agent\")\n",
    "review_agent = FunctionImplementationAgent(review_chain, state_change_callback=state_callback, name=\"Review Agent\")\n",
    "agent = SequentialAgent([code_agent, doc_agent, review_agent], state_change_callback=state_callback, name=\"Sequential Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01a7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running agent Code Agent\n",
      "running agent Docstring Agent\n",
      "running agent Review Agent\n",
      "idle\n",
      "query='Write a python function to find the biggest but not exceed the given integer number. The found number must be a number in Fibonacci array.' origin='Sequential Agent' response='```' responses=None context=None execution_result='success' error_message=None\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = \"Write a python function to find the biggest but not exceed the given integer number. The found number must be a number in Fibonacci array.\"\n",
    "message = agent.execute(AgentMessage(query=query), max_new_tokens=16384)\n",
    "\n",
    "print(message)\n",
    "print(message.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-design-pattern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
