{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe6fa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hf_models/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import environ\n",
    "\n",
    "environ.setdefault(\"HF_HOME\", \"/data/hf_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082bf96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/agent_design_pattern/src/transformers/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from a2a.types import AgentCapabilities, AgentCard, AgentSkill\n",
    "from adp_core.agent import AgentMessage, BaseAgent\n",
    "from adp_core.chain import BaseLLMChain\n",
    "from adp_core.orchestration import DebateAgent\n",
    "from adp_transformers.chain import ChatCausalMultiTurnsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784abc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(BaseAgent):\n",
    "    chain: BaseLLMChain\n",
    "\n",
    "    def execute(self, message: AgentMessage, **kwargs) -> AgentMessage:\n",
    "        self.state = \"running\"\n",
    "        message = self.chain.invoke(message, **kwargs)\n",
    "        message.execution_result = \"success\"\n",
    "        message.origin = self.card.name\n",
    "        self.state = \"idle\"\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0b069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]\n",
      "CUDA-fused xIELU not available (No module named 'xielu') – falling back to a Python version.\n",
      "For CUDA xIELU (experimental), `pip install git+https://github.com/nickjbrowning/XIELU`\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.86s/it]\n",
      "The fast path is not available because one of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n"
     ]
    }
   ],
   "source": [
    "# System prompts generated by Gemini\n",
    "system_prompt_1 = \"\"\"You are a Arboreal Protector who is an elite environmental agent dedicated to combating the complex challenges threatening the world's forests and vital ecosystems. Specializing in issues from illegal logging and rampant deforestation to the impacts of climate change and invasive species, this operative combines deep ecological knowledge with advanced surveillance and strategic planning. They are adept at navigating dense wilderness for fieldwork, utilizing remote sensing technologies to monitor forest health, and coordinating international efforts to secure protected areas. Whether tracking illicit timber operations or developing sustainable land management plans alongside local communities, the Arboreal Protector is the vigilant, resourceful shield ensuring the longevity and biodiversity of our planet's indispensable woodlands.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_2 = \"\"\"You are a Fauna Guardian who is a highly specialized environmental operative focused on the urgent protection of endangered animal species, their critical habitats, and the prevention of biodiversity loss. This agent possesses a unique blend of veterinary medicine, behavioral ecology, and conservation law expertise, enabling them to tackle immediate threats like poaching, habitat fragmentation, and wildlife trafficking. Their work involves conducting clandestine anti-poaching missions, establishing and maintaining safe breeding programs, and using sophisticated tracking technology to monitor at-risk populations. The Fauna Guardian collaborates closely with global scientific bodies and local rangers, acting as the crucial frontline defender committed to ensuring that vulnerable species, from keystone predators to delicate endemic organisms, are safeguarded from the precipice of extinction.\"\"\"\n",
    "\n",
    "system_prompt_3 = \"\"\"You are an industrial Decarbonization Strategist who is an expert in corporate and industrial governance, keenly focused on guiding large-scale enterprises toward achieving rigorous Net Zero goals and fundamentally greening their production processes. This professional excels at integrating sustainability mandates directly into high-level business strategy, supply chain management, and regulatory compliance frameworks. They possess deep knowledge of carbon accounting, renewable energy procurement, and the deployment of circular economy principles to minimize waste and resource consumption. The Strategist’s role is to bridge the gap between financial performance and ecological responsibility, advising boards and executive teams on the necessary technological transitions and operational shifts required to make industrial output truly \"Greenery,\" ensuring profitability aligns with a verifiable, accelerated path toward climate neutrality.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"{query}\n",
    "\"\"\"\n",
    "\n",
    "def state_callback(state: str):\n",
    "    print(f\"agent state: {state}\")\n",
    "\n",
    "agent1_skill = AgentSkill(\n",
    "    id='agent1-skill',\n",
    "    name=\"agent1 skill\",\n",
    "    description=\"self-agent1 skill\",\n",
    "    tags=['agent1']\n",
    ")\n",
    "agent1_card = AgentCard(\n",
    "    name=\"agent1\",\n",
    "    description=\"self-agent1 agent\",\n",
    "    skills=[agent1_skill],\n",
    "    capabilities=AgentCapabilities(),\n",
    "    default_input_modes=['text'],\n",
    "    default_output_modes=['text'],\n",
    "    url=\"localhost\",\n",
    "    version=\"0.1.0\"\n",
    ")\n",
    "agent2_skill = AgentSkill(\n",
    "    id='agent2-skill',\n",
    "    name=\"agent2 skill\",\n",
    "    description=\"self-agent2 skill\",\n",
    "    tags=['agent2']\n",
    ")\n",
    "agent2_card = AgentCard(\n",
    "    name=\"agent2\",\n",
    "    description=\"self-agent2 agent\",\n",
    "    skills=[agent2_skill],\n",
    "    capabilities=AgentCapabilities(),\n",
    "    default_input_modes=['text'],\n",
    "    default_output_modes=['text'],\n",
    "    url=\"localhost\",\n",
    "    version=\"0.1.0\"\n",
    ")\n",
    "agent3_skill = AgentSkill(\n",
    "    id='agent3-skill',\n",
    "    name=\"agent3 skill\",\n",
    "    description=\"self-agent3 skill\",\n",
    "    tags=['agent3']\n",
    ")\n",
    "agent3_card = AgentCard(\n",
    "    name=\"agent3\",\n",
    "    description=\"self-agent3 agent\",\n",
    "    skills=[agent3_skill],\n",
    "    capabilities=AgentCapabilities(),\n",
    "    default_input_modes=['text'],\n",
    "    default_output_modes=['text'],\n",
    "    url=\"localhost\",\n",
    "    version=\"0.1.0\"\n",
    ")\n",
    "debate_skill = AgentSkill(\n",
    "    id='debate-skill',\n",
    "    name=\"debate skill\",\n",
    "    description=\"self-debate skill\",\n",
    "    tags=['debate']\n",
    ")\n",
    "debate_card = AgentCard(\n",
    "    name=\"debate agent\",\n",
    "    description=\"self-debate agent\",\n",
    "    skills=[debate_skill],\n",
    "    capabilities=AgentCapabilities(),\n",
    "    default_input_modes=['text'],\n",
    "    default_output_modes=['text'],\n",
    "    url=\"localhost\",\n",
    "    version=\"0.1.0\"\n",
    ")\n",
    "\n",
    "# Include all history\n",
    "chain1 = ChatCausalMultiTurnsChain(\n",
    "    model=\"HuggingFaceTB/SmolLM3-3B\",\n",
    "    system_prompt=system_prompt_1,\n",
    "    user_prompt_template=user_prompt,\n",
    "    device=\"cuda\",\n",
    "    max_new_tokens=4096,\n",
    "    include_history=-1)\n",
    "chain2 = ChatCausalMultiTurnsChain(\n",
    "    model=\"swiss-ai/Apertus-8B-Instruct-2509\",\n",
    "    system_prompt=system_prompt_2,\n",
    "    user_prompt_template=user_prompt,\n",
    "    device=\"cuda\",\n",
    "    max_new_tokens=4096,\n",
    "    include_history=-1)\n",
    "chain3 = ChatCausalMultiTurnsChain(\n",
    "    model=\"ibm-granite/granite-4.0-h-1b\",\n",
    "    system_prompt=system_prompt_3,\n",
    "    user_prompt_template=user_prompt,\n",
    "    device=\"cuda\",\n",
    "    max_new_tokens=4096,\n",
    "    include_history=-1)\n",
    "\n",
    "agent1 = Agent(chain=chain1, card=agent1_card, state_change_callback=state_callback)\n",
    "agent2 = Agent(chain=chain2, card=agent2_card, state_change_callback=state_callback)\n",
    "agent3 = Agent(chain=chain3, card=agent3_card, state_change_callback=state_callback)\n",
    "\n",
    "debate_agent = DebateAgent(agents=[agent1, agent2, agent3], card=debate_card, pick_strategy=\"round_robin\", max_turns=7, state_change_callback=state_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8f58c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 0: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 0: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 0: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent2 running/((agent1:idle)-(agent2:running)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 2: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 2: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n",
      "agent state: debate agent:turn 2: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 3: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 3: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 3: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent2 running/((agent1:idle)-(agent2:running)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 5: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 5: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n",
      "agent state: debate agent:turn 5: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 6: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 6: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 6: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:idle/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "message len: 7\n",
      "agent1\n",
      "<think>\n",
      "Okay, the user is asking for a solution to the problem of global warming. Let me\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "As a Fauna Guardian, my primary focus is on protecting endangered species and their habitats. However, I\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "I'm glad you reached out about addressing global warming. While I can't provide a solution as a\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "I understand the importance of addressing global warming. As an Arboreal Protector, my expertise lies in preserving\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "I'm sorry for any confusion, but as a Fauna Guardian, my primary focus is on protecting endangered\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "I'm sorry for any confusion, but as a\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "I'm here to help with any questions you have about global warming and the challenges it poses to our\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "debate_agent.max_turns = 7\n",
    "debate_agent.pick_strategy = \"round_robin\"\n",
    "\n",
    "query = \"Propose a solution to the problem of global warming.\"\n",
    "\n",
    "message = debate_agent.execute(AgentMessage(query=query))\n",
    "\n",
    "print(f\"message len: {len(message.responses)}\")\n",
    "for agent_name, response in message.responses:\n",
    "    print(f\"{agent_name}\\n{response}\")\n",
    "    print(\"-\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3044956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 0: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 0: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n",
      "agent state: debate agent:turn 0: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 2: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 2: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 2: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 3: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 3: agent agent2 running/((agent1:idle)-(agent2:running)-(agent3:idle))\n",
      "agent state: debate agent:turn 3: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 5: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 5: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n",
      "agent state: debate agent:turn 5: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:idle/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "message len: 5\n",
      "agent3\n",
      "As an industrial decarbonization strategist, I would propose a multi-faceted solution to address the\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "\n",
      "As an industrial decarbonization strategist, I would propose a multi-faceted\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "Solution to address the rapid melting of the polar ice caps:\n",
      "\n",
      "1. **Transition to Renewable Energy**:\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "As a Fauna Guardian, my primary focus is on the protection of endangered species and their habitats. However\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "As a Fauna Guardian, my primary focus is on the protection of endangered species and their habitats.\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "debate_agent.max_turns = 6\n",
    "debate_agent.pick_strategy = \"random\"\n",
    "debate_agent.random_seed = 2025\n",
    "\n",
    "query = \"The ice of the northpole is melting faster than before in recent decades. Poeple even witness the melting of the eternal ice. Propose a solution related to your field to potentially slow down this process.\"\n",
    "message = debate_agent.execute(AgentMessage(query=query))\n",
    "\n",
    "print(f\"message len: {len(message.responses)}\")\n",
    "for agent_name, response in message.responses:\n",
    "    print(f\"{agent_name}\\n{response}\")\n",
    "    print(\"-\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f928884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 0: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 0: all agents running/((agent1:running)|(agent2:idle)|(agent3:idle))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 0: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 0: all agents running/((agent1:idle)|(agent2:running)|(agent3:idle))\n",
      "agent state: debate agent:turn 0: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 0: all agents running/((agent1:idle)|(agent2:idle)|(agent3:running))\n",
      "agent state: debate agent:turn 0: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 3: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 3: all agents running/((agent1:running)|(agent2:idle)|(agent3:idle))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 3: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 3: all agents running/((agent1:idle)|(agent2:running)|(agent3:idle))\n",
      "agent state: debate agent:turn 3: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 3: all agents running/((agent1:idle)|(agent2:idle)|(agent3:running))\n",
      "agent state: debate agent:turn 3: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 6: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 6: all agents running/((agent1:running)|(agent2:idle)|(agent3:idle))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 6: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 6: all agents running/((agent1:idle)|(agent2:running)|(agent3:idle))\n",
      "agent state: debate agent:turn 6: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:turn 6: all agents running/((agent1:idle)|(agent2:idle)|(agent3:running))\n",
      "agent state: debate agent:turn 6: all agents running/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "agent state: debate agent:idle/((agent1:idle)|(agent2:idle)|(agent3:idle))\n",
      "message len: 9\n",
      "agent1\n",
      "\n",
      "Addressing the crisis of contaminated water and its subsequent effects on water quality, desert\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "1. Wasting Water:\n",
      "   - Implementing smart water management systems that can detect leaks and ine\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "To address the problem of water contamination and its impact on our environment, we can propose a comprehensive solution\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "To tackle the issue of contaminated water, we can implement a multi-faceted approach that focuses on\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "1. Wasting Water:\n",
      "   - Implementing smart water management systems that can detect leaks and ine\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "1. Wasting Water:\n",
      "   - Implementing smart water management systems that can detect leaks and\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "To combat the problem of contaminated water, we can adopt a multi-pronged approach that addresses the\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "To address the problem of contaminated water and its impact on our environment, we can propose a comprehensive solution\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "1. Wasting Water:\n",
      "   - Implementing smart water management systems that can detect leaks and\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "debate_agent.max_turns = 8\n",
    "debate_agent.pick_strategy = \"simultaneous\"\n",
    "\n",
    "query = \"\"\"Water is a precious resource for our human kind and our planet. Since industrial revolution, industrial and human activity is increasingly contaminate the water source. Propose a solution to decline this problem in 3 aspects:\n",
    "- Wasting water\n",
    "- The quality of water after people have used and sent back to the environment\n",
    "- Desertification\"\"\"\n",
    "message = debate_agent.execute(AgentMessage(query=query))\n",
    "\n",
    "print(f\"message len: {len(message.responses)}\")\n",
    "for agent_name, response in message.responses:\n",
    "    print(f\"{agent_name}\\n{response}\")\n",
    "    print(\"-\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056cec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 0: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 0: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 0: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent2 running/((agent1:idle)-(agent2:running)-(agent3:idle))\n",
      "agent state: debate agent:turn 1: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 2: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 2: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 2: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 3: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 3: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 3: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent2 running/((agent1:idle)-(agent2:running)-(agent3:idle))\n",
      "agent state: debate agent:turn 4: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 5: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 5: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 5: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 6: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 6: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:running))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent state: debate agent:turn 6: agent agent3 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 7: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 7: agent agent2 running/((agent1:idle)-(agent2:running)-(agent3:idle))\n",
      "agent state: debate agent:turn 7: agent agent2 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 8: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 8: agent agent1 running/((agent1:running)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:turn 8: agent agent1 running/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "agent state: debate agent:idle/((agent1:idle)-(agent2:idle)-(agent3:idle))\n",
      "message len: 9\n",
      "agent3\n",
      "To address the growing issue of plastic pollution in our oceans, a multi-faceted approach is necessary\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "1. **Implement Extended Producer Responsibility (EPR):** This policy requires manufacturers to take responsibility\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "To address the growing issue of plastic pollution in our oceans, a multi-faceted approach is necessary\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "1. **Implement Extended Producer Responsibility (EPR):** This policy requires manufacturers to take responsibility\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "To address the growing issue of plastic pollution in our oceans, a multi-faceted approach is necessary\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "1. **Implement Extended Producer Responsibility (EPR):** This policy requires manufacturers to take responsibility for\n",
      "--------------------------------------------------\n",
      "\n",
      "agent3\n",
      "To address the growing issue of plastic pollution in our oceans, a multi-faceted approach is necessary\n",
      "--------------------------------------------------\n",
      "\n",
      "agent2\n",
      "To address the growing issue of plastic pollution in our oceans, a multi-faceted approach is necessary\n",
      "--------------------------------------------------\n",
      "\n",
      "agent1\n",
      "1. **Implement Extended Producer Responsibility (EPR):** This policy requires manufacturers to take responsibility for\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "n = 0\n",
    "def reversed_agent_strategy(agents: Sequence[BaseAgent]) -> BaseAgent:\n",
    "    global n\n",
    "    n -= 1\n",
    "    return agents[n % len(agents)]\n",
    "\n",
    "debate_agent.max_turns = 9\n",
    "debate_agent.pick_strategy = reversed_agent_strategy\n",
    "\n",
    "query = \"In recent reports, reasearchers have analyzed the plastic pollution in water including lakes, oceans. The study found an average concentration of nanoplastic near coastlines of 25 milligrams per cubic meter of water. Nanoplastics are tiny enough that they can easily infiltrate the bodies of living creatures. For fish and other animals that live in the ocean, that means constant exposure that builds up over time. Propose a solution for better management of plastic waste in the near future.\"\n",
    "message = debate_agent.execute(AgentMessage(query=query))\n",
    "\n",
    "print(f\"message len: {len(message.responses)}\")\n",
    "for agent_name, response in message.responses:\n",
    "    print(f\"{agent_name}\\n{response}\")\n",
    "    print(\"-\" * 50)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
